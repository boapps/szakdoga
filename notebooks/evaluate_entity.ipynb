{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a4973c9-3d89-4f98-8e41-ba135bf2f03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow._fs.FileInfo size changed, may indicate binary incompatibility. Expected 64 from C header, got 88 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow._fs.FileSelector size changed, may indicate binary incompatibility. Expected 48 from C header, got 72 from PyObject\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f54b4d9-ab05-49c3-b030-5ec744dd5480",
   "metadata": {},
   "outputs": [],
   "source": [
    "institutions_dataset = load_from_disk('../datasets/intermediate/institutions_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98f0cd87-73d8-41db-aba1-012e3825b88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text', 'corrupt_institutions', 'not_corrupt_institutions'],\n",
       "        num_rows: 494\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['text', 'corrupt_institutions', 'not_corrupt_institutions'],\n",
       "        num_rows: 7191\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'corrupt_institutions', 'not_corrupt_institutions'],\n",
       "        num_rows: 919\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "institutions_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0b9e716-ae23-408c-86f3-f0f8a1ee2fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Belföld\\nAz MSZP-vel fizettetné vissza Simon pénzét a Fidesz\\nA Fidesz szerint, ha Simon Gábor, a szocialista párt volt elnökhelyettese nem fizeti vissza az összeférhetetlensége idején felvett 39 millió forintos parlamenti jövedelmét, akkor ezt az MSZP-nek kell megtennie helyette.\\nGulyás Gergely, a kormánypárt országgyűlési képviselője pénteki budapesti sajtótájékoztatóján emlékeztetett, hogy Simon Gábor az elmúlt években egyik vagyonnyilatkozatában sem tüntette fel a titkos bécsi számlán 2008 óta tartott több mint 240 millió forintos vagyont.\\nHa emiatt az Országgyűlés megállapította volna az összeférhetetlenségét, vissza kellett volna fizetnie az ez idő alatt felvett parlamenti jövedelmét, 39 millió forintot - magyarázta a Fidesz képviselője, aki szerint Simon Gábor éppen azért mondott le február 13-án (még mielőtt kimondták volna az összeférhetetlenséget) a mandátumáról, hogy ezt ne kelljen megtennie.\\nA Fidesz most arra szólítja fel Simon Gábort és az MSZP-t, hogy előzzék meg a pénz visszakövetelésének sokéves procedúráját, és fizessék vissza a csaknem 40 milliós jövedelmet. Ha ezt Simon nem teszi meg, az MSZP-nek kell helyette, mert a pártnak is van felelőssége az ügyben, a 39 millió forintért politikai értelemben nekik is helyt kell állniuk - közölte Gulyás Gergely.\\nEmlékeztetett, hogy a mentelmi bizottság egyébként keresi a fizetés visszakövetelésének jogi lehetőségét, és már megérkezett a testülethez az erről szóló pécsi egyetemi szakvélemény, amely a bizottság jelentésének elkészültekor - amelynek határideje március 31. - lesz nyilvános. Hozzátette, személyes véleménye az, hogy Simon Gábor a lemondással nem mentesülhet a visszafizetési kötelezettség alól.\\nGulyás Gergely azt is hangsúlyozta, úgy tűnik, hogy \"az MSZP-nek titkolnivalója van az ügyben\", a párt és elnöke, Mesterházy Attila nem segíti a helyzet tisztázását.\\nA Fidesz politikusát arról is kérdezték, hogy az Együtt-PM az Országgyűlés több bizottságának soron kívüli összehívását kezdeményezi arra hivatkozva, hogy a Simon-üggyel összefüggésbe hozott vállalkozó, Welsz Tamás váratlan halála \"egy gyanús ügy újabb, gyanús fejleménye\".\\nA kormánypárti képviselő erre azt mondta, egyelőre nem tud olyan információról, amely indokolttá tenné az Együtt-PM által kért egyik testület, a nemzetbiztonsági bizottság összehívását.',\n",
       " 'corrupt_institutions': ['MSZP'],\n",
       " 'not_corrupt_institutions': []}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "institutions_dataset['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e837cef-8c1b-4e30-b7e0-b94c00f9ce2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "institutions_dataset = institutions_dataset.map(lambda row: {'all': row['corrupt_institutions'] + row['not_corrupt_institutions']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "363ab6f3-c43e-4a99-9f68-e2a0b628e325",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keyword_generation_task_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mkeyword_generation_task_dataset\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'keyword_generation_task_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "text = keyword_generation_task_dataset['test'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2097e8ee-9553-412c-8e29-fbc4e6061277",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "model_id = \"huggyllama/llama-7b\"\n",
    "peft_model_id = '../finetune/qlora-combined_people_institution-7b-v1.0.0/checkpoint-1131/adapter_model'\n",
    "peft_model_id = '../finetune/qlora-out-entity-extraction'\n",
    "\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    load_in_4bit=True,\n",
    "    device_map='auto',\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type='nf4'\n",
    "    ),\n",
    ")\n",
    "model = PeftModel.from_pretrained(model, peft_model_id)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4253205-88d8-48d7-a6dd-1dcbfc7f030f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "device = 'cuda:0'\n",
    "# features: ['text', 'corrupt_institutions', 'not_corrupt_institutions', 'all'],\n",
    "institution_classification_prompt = '''[intézmény klasszifikáció]\n",
    "{text}\n",
    "\n",
    "###\n",
    "\n",
    "összes: {all}\n",
    "korrupcióban érintett:'''\n",
    "\n",
    "tp = 0\n",
    "fp = 0\n",
    "tn = 0\n",
    "fn = 0\n",
    "\n",
    "for row in tqdm(institutions_dataset['test']):\n",
    "    text = row['text']\n",
    "    corrupt_institutions = row['corrupt_institutions']\n",
    "    not_corrupt_institutions = row['not_corrupt_institutions']\n",
    "    all_institutions = row['all']\n",
    "    input_text = institution_classification_prompt.format(all=', '.join(all_institutions), text=text)\n",
    "    with torch.cuda.amp.autocast():\n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "        if len(inputs['input_ids'][0]) > 2048:\n",
    "            continue\n",
    "        outputs = model.generate(input_ids=inputs['input_ids'], max_new_tokens=200, penalty_alpha=0.6, top_k=3)\n",
    "        result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        sresult = result[result.rfind(':')+2:].strip()\n",
    "        output_labels = sresult.strip().split(', ')\n",
    "        for institution in corrupt_institutions:\n",
    "            if institution in output_labels:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "        for institution in not_corrupt_institutions:\n",
    "            if institution in output_labels:\n",
    "                fp += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "        print(tp, tn, fp, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72e1d5c-de97-4109-a17e-bebebb4df8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('precision', tp/(tp+fp))\n",
    "print('recall', tp/(tp+fn))\n",
    "print('accuracy', (tp+tn)/(tp+tn+fp+fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcabc4b-94a4-4dad-9723-27c5a5f7e756",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_possible_labels = set()\n",
    "for labels in truths:\n",
    "    for label in labels:\n",
    "        all_possible_labels.add(label)\n",
    "for labels in preds:\n",
    "    for label in labels:\n",
    "        all_possible_labels.add(label)\n",
    "label_to_id = {key: value for value, key in enumerate(all_possible_labels)}\n",
    "label_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ee5383-fa86-4c82-bfa9-edf722279260",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_preds = [[1 if value in preds_a else 0 for value in label_to_id] for preds_a in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dd8856-1149-47fa-b24f-3e7831f037a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb486a9-4b57-4829-a50c-8cab0cf56d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_truths = [[1 if value in truths_a else 0 for value in label_to_id] for truths_a in truths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248d1c97-5b75-44aa-9424-645af20d504d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(i_truths, i_preds, target_names=label_to_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18866395-d19f-4ffa-a7f0-25f8873630b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f1, _ = precision_recall_fscore_support(i_truths, i_preds)\n",
    "acc = accuracy_score(labels, preds)\n",
    "{\n",
    "    'accuracy': acc,\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1': f1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddf2ec0-c300-4c10-b6d6-be87c5a0c5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_true = np.array([[0, 1, 1, 1],[0,0,1,0],[1,1,0,0]])\n",
    "y_scores = np.array([[0.2, 0.6, 0.1, 0.8],[0.4,0.9,0.8,0.6],[0.8,0.4,0.5,0.7]])\n",
    "threshold = 0.5\n",
    "y_pred=[]\n",
    "for sample in  y_scores:\n",
    "  y_pred.append([1 if i>=0.5 else 0 for i in sample ] )\n",
    "y_pred = np.array(y_pred)\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08b549b-4b21-4fa2-928e-1cb2645a43b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(i_truths, i_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3819e977-a89c-484a-87b5-8ee34e1b8b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Actual \\n\", y_true)\n",
    "print(\"\\nPredicted \\n\",y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d29fc19-eabd-4c8f-b172-ac1d28ee37b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "multilabel_confusion_matrix(i_truths, i_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff385130-1c58-4a7c-8e72-a8767fac40bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
