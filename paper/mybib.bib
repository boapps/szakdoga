@inproceedings{
	hu2022lora,
	title={Lo{RA}: Low-Rank Adaptation of Large Language Models},
	author={Edward J Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
	booktitle={International Conference on Learning Representations},
	year={2022},
	url={https://openreview.net/forum?id=nZeVKeeFYf9}
}


@article{bert,
	author       = {Jacob Devlin and
	Ming{-}Wei Chang and
	Kenton Lee and
	Kristina Toutanova},
	title        = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
	Understanding},
	journal      = {CoRR},
	volume       = {abs/1810.04805},
	year         = {2018},
	url          = {http://arxiv.org/abs/1810.04805},
	eprinttype    = {arXiv},
	eprint       = {1810.04805},
	timestamp    = {Tue, 30 Oct 2018 20:39:56 +0100},
	biburl       = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{gpt4,
	title={GPT-4 Technical Report}, 
	author={OpenAI},
	year={2023},
	eprint={2303.08774},
	archivePrefix={arXiv},
	primaryClass={cs.CL}
}

@article{gpt3,
	author       = {Tom B. Brown and
	Benjamin Mann and
	Nick Ryder and
	Melanie Subbiah and
	Jared Kaplan and
	Prafulla Dhariwal and
	Arvind Neelakantan and
	Pranav Shyam and
	Girish Sastry and
	Amanda Askell and
	Sandhini Agarwal and
	Ariel Herbert{-}Voss and
	Gretchen Krueger and
	Tom Henighan and
	Rewon Child and
	Aditya Ramesh and
	Daniel M. Ziegler and
	Jeffrey Wu and
	Clemens Winter and
	Christopher Hesse and
	Mark Chen and
	Eric Sigler and
	Mateusz Litwin and
	Scott Gray and
	Benjamin Chess and
	Jack Clark and
	Christopher Berner and
	Sam McCandlish and
	Alec Radford and
	Ilya Sutskever and
	Dario Amodei},
	title        = {Language Models are Few-Shot Learners},
	journal      = {CoRR},
	volume       = {abs/2005.14165},
	year         = {2020},
	url          = {https://arxiv.org/abs/2005.14165},
	eprinttype    = {arXiv},
	eprint       = {2005.14165},
	timestamp    = {Thu, 25 May 2023 10:38:31 +0200},
	biburl       = {https://dblp.org/rec/journals/corr/abs-2005-14165.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{gpt2,
	title={Language Models are Unsupervised Multitask Learners},
	author={Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
	year={2019}
}

@inproceedings{gpt1,
	title={Improving Language Understanding by Generative Pre-Training},
	author={Alec Radford and Karthik Narasimhan},
	year={2018},
	url={https://api.semanticscholar.org/CorpusID:49313245}
}

@misc{instructgpt,
	title={Training language models to follow instructions with human feedback}, 
	author={Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
	year={2022},
	eprint={2203.02155},
	archivePrefix={arXiv},
	primaryClass={cs.CL}
}

@article{transformers,
	author       = {Thomas Wolf and
	Lysandre Debut and
	Victor Sanh and
	Julien Chaumond and
	Clement Delangue and
	Anthony Moi and
	Pierric Cistac and
	Tim Rault and
	R{\'{e}}mi Louf and
	Morgan Funtowicz and
	Jamie Brew},
	title        = {HuggingFace's Transformers: State-of-the-art Natural Language Processing},
	journal      = {CoRR},
	volume       = {abs/1910.03771},
	year         = {2019},
	url          = {http://arxiv.org/abs/1910.03771},
	eprinttype    = {arXiv},
	eprint       = {1910.03771},
	timestamp    = {Tue, 02 Jun 2020 12:49:01 +0200},
	biburl       = {https://dblp.org/rec/journals/corr/abs-1910-03771.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@online{ahalo,
	author    = {Merényi M. Miklós and Vincze Orsolya},
	title     = {a Háló},
	year      = {2023},
	url       = {http://www.ahalo.hu},
	note      = {\url{http://www.ahalo.hu}},
}

@misc{newspaper3k,
	author    = {Lucas Ou-Yang},
	title     = {newspaper3k},
	year      = {2020},
	url       = {https://github.com/codelucas/newspaper},
	note      = {\url{https://github.com/codelucas/newspaper}},
}

@misc{qlora,
	title={QLoRA: Efficient Finetuning of Quantized LLMs}, 
	author={Tim Dettmers and Artidoro Pagnoni and Ari Holtzman and Luke Zettlemoyer},
	year={2023},
	eprint={2305.14314},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}

@inproceedings{vincze-etal-2010-hungarian,
	title = "{H}ungarian Dependency Treebank",
	author = {Vincze, Veronika  and
	Szauter, D{\'o}ra  and
	Alm{\'a}si, Attila  and
	M{\'o}ra, Gy{\"o}rgy  and
	Alexin, Zolt{\'a}n  and
	Csirik, J{\'a}nos},
	editor = "Calzolari, Nicoletta  and
	Choukri, Khalid  and
	Maegaard, Bente  and
	Mariani, Joseph  and
	Odijk, Jan  and
	Piperidis, Stelios  and
	Rosner, Mike  and
	Tapias, Daniel",
	booktitle = "Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10)",
	month = may,
	year = "2010",
	address = "Valletta, Malta",
	publisher = "European Language Resources Association (ELRA)",
	url = "http://www.lrec-conf.org/proceedings/lrec2010/pdf/465_Paper.pdf",
	abstract = "Herein, we present the process of developing the first Hungarian Dependency TreeBank. First, short references are made to dependency grammars we considered important in the development of our Treebank. Second, mention is made of existing dependency corpora for other languages. Third, we present the steps of converting the Szeged Treebank into dependency-tree format: from the originally phrase-structured treebank, we produced dependency trees by automatic conversion, checked and corrected them thereby creating the first manually annotated dependency corpus for Hungarian. We also go into detail about the two major sets of problems, i.e. coordination and predicative nouns and adjectives. Fourth, we give statistics on the treebank: by now, we have completed the annotation of business news, newspaper articles, legal texts and texts in informatics, at the same time, we are planning to convert the entire corpus into dependency tree format. Finally, we give some hints on the applicability of the system: the present database may be utilized ― among others ― in information extraction and machine translation as well.",
}

@misc{ud-hungarian-szeged,
	title={UD Hungarian Szeged}, 
	author={Richárd, Farkas and Katalin, Simkó and Zsolt, Szántó and Viktor, Varga and Veronika, Vincze},
	year={2022},
	url={https://universaldependencies.org/treebanks/hu_szeged/index.html}
}

@misc{llama.cpp,
	title={llama.cpp},
	author={Georgi Gerganov},
	year={2023},
	url={https://github.com/ggerganov/llama.cpp}
}

@article{spacy,
	author = {Honnibal, Matthew and Montani, Ines and Van Landeghem, Sofie and Boyd, Adriane},
	doi = {10.5281/zenodo.1212303},
	title = {{spaCy: Industrial-strength Natural Language Processing in Python}},
	year = {2020}
}

@inproceedings{nerkor,
	author    = {Eszter Simon and
	No{\'{e}}mi Vad{\'{a}}sz},
	editor    = {Kamil Ekstein and
	Frantisek P{\'{a}}rtl and
	Miloslav Konop{\'{\i}}k},
	title     = {Introducing NYTK-NerKor, {A} Gold Standard Hungarian Named Entity
	Annotated Corpus},
	booktitle = {Text, Speech, and Dialogue - 24th International Conference, {TSD}
	2021, Olomouc, Czech Republic, September 6-9, 2021, Proceedings},
	series    = {Lecture Notes in Computer Science},
	volume    = {12848},
	pages     = {222--234},
	publisher = {Springer},
	year      = {2021},
	doi       = {10.1007/978-3-030-83527-9\_19},
}
@inproceedings{szarvas-etal-2006-highly,
	title = "A highly accurate Named Entity corpus for {H}ungarian",
	author = {Szarvas, Gy{\"o}rgy  and
	Farkas, Rich{\'a}rd  and
	Felf{\"o}ldi, L{\'a}szl{\'o}  and
	Kocsor, Andr{\'a}s  and
	Csirik, J{\'a}nos},
	editor = "Calzolari, Nicoletta  and
	Choukri, Khalid  and
	Gangemi, Aldo  and
	Maegaard, Bente  and
	Mariani, Joseph  and
	Odijk, Jan  and
	Tapias, Daniel",
	booktitle = "Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06)",
	month = may,
	year = "2006",
	address = "Genoa, Italy",
	publisher = "European Language Resources Association (ELRA)",
	url = "http://www.lrec-conf.org/proceedings/lrec2006/pdf/365_pdf.pdf",
	abstract = "A highly accurate Named Entity (NE) corpus for Hungarian that is publicly available for research purposes is introduced in the paper, along with its main properties. The results of experiments that apply various Machine Learning models and classifier combination schemes are also presented to serve as a benchmark for further research based on the corpus. The data is a segment of the Szeged Corpus (Csendes et al., 2004), consisting of short business news articles collected from MTI (Hungarian News Agency, www.mti.hu). The annotation procedure was carried out paying special attention to annotation accuracy. The corpus went through a parallel annotation phase done by two annotators, resulting in a tagging with inter-annotator agreement rate of 99.89{\%}. Controversial taggings were collected and discussed by the two annotators and a linguist with several years of experience in corpus annotation. These examples were tagged following the decision they made together, and finally all entities that had suspicious or dubious annotations were collected and checked for consistency. We consider the result of this correcting process virtually be free of errors. Our best performing Named Entity Recognizer (NER) model attained an accuracy of 92.86{\%} F measure on the corpus.",
}

@article{huspacy,
	author = {Orosz, György and Szabó, Gergő and Berkecz, Péter and Szántó, Zsolt and Farkas, Richárd},
	doi = {10.1007/978-3-031-40498-6_6},
	journal = {Text, Speech, and Dialogue: TSD 2023. Lecture Notes in Computer Science},
	pages = {58--69},
	title = {{Advancing Hungarian Text Processing with HuSpaCy: Efficient and Accurate NLP Pipelines}},
	volume = {14102},
	year = {2023}
}

@InProceedings{ Nemeskey:2021a,
	author = {Nemeskey, Dávid Márk},
	title = {Introducing \texttt{huBERT}},
	booktitle = {{XVII}.\ Magyar Sz{\'a}m{\'i}t{\'o}g{\'e}pes Nyelv{\'e}szeti Konferencia ({MSZNY}2021)},
	year = 2021,
	pages = {TBA},
	address = {Szeged},
}

@misc{jamie,
	title={JaMIE: A Pipeline Japanese Medical Information Extraction System}, 
	author={Fei Cheng and Shuntaro Yada and Ribeka Tanaka and Eiji Aramaki and Sadao Kurohashi},
	year={2021},
	eprint={2111.04261},
	archivePrefix={arXiv},
	primaryClass={cs.CL}
}

@ARTICLE{twitter-traffic,
	author={Das, Rahul Deb and Purves, Ross S.},
	journal={IEEE Transactions on Intelligent Transportation Systems}, 
	title={Exploring the Potential of Twitter to Understand Traffic Events and Their Locations in Greater Mumbai, India}, 
	year={2020},
	volume={21},
	number={12},
	pages={5213-5222},
	doi={10.1109/TITS.2019.2950782}}

@inproceedings{resin,
	title = "{RESIN}: A Dockerized Schema-Guided Cross-document Cross-lingual Cross-media Information Extraction and Event Tracking System",
	author = "Wen, Haoyang  and
	Lin, Ying  and
	Lai, Tuan  and
	Pan, Xiaoman  and
	Li, Sha  and
	Lin, Xudong  and
	Zhou, Ben  and
	Li, Manling  and
	Wang, Haoyu  and
	Zhang, Hongming  and
	Yu, Xiaodong  and
	Dong, Alexander  and
	Wang, Zhenhailong  and
	Fung, Yi  and
	Mishra, Piyush  and
	Lyu, Qing  and
	Sur{\'\i}s, D{\'\i}dac  and
	Chen, Brian  and
	Brown, Susan Windisch  and
	Palmer, Martha  and
	Callison-Burch, Chris  and
	Vondrick, Carl  and
	Han, Jiawei  and
	Roth, Dan  and
	Chang, Shih-Fu  and
	Ji, Heng",
	editor = "Sil, Avi  and
	Lin, Xi Victoria",
	booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Demonstrations",
	month = jun,
	year = "2021",
	address = "Online",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/2021.naacl-demos.16",
	doi = "10.18653/v1/2021.naacl-demos.16",
	pages = "133--143",
	abstract = "We present a new information extraction system that can automatically construct temporal event graphs from a collection of news documents from multiple sources, multiple languages (English and Spanish for our experiment), and multiple data modalities (speech, text, image and video). The system advances state-of-the-art from two aspects: (1) extending from sentence-level event extraction to cross-document cross-lingual cross-media event extraction, coreference resolution and temporal event tracking; (2) using human curated event schema library to match and enhance the extraction output. We have made the dockerlized system publicly available for research purpose at GitHub, with a demo video.",
}


@article{transformer,
	author       = {Ashish Vaswani and
	Noam Shazeer and
	Niki Parmar and
	Jakob Uszkoreit and
	Llion Jones and
	Aidan N. Gomez and
	Lukasz Kaiser and
	Illia Polosukhin},
	title        = {Attention Is All You Need},
	journal      = {CoRR},
	volume       = {abs/1706.03762},
	year         = {2017},
	url          = {http://arxiv.org/abs/1706.03762},
	eprinttype    = {arXiv},
	eprint       = {1706.03762},
	timestamp    = {Sat, 23 Jan 2021 01:20:40 +0100},
	biburl       = {https://dblp.org/rec/journals/corr/VaswaniSPUJGKP17.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}

